# 5.3 Hyperparameters and Validation Sets
## Hyperparameters
하이퍼 파라미터는 모델링 할 때 사용자가 직접 세팅해주는 값을 뜻한다. learning rate나 서포트 벡터 머신에서의 C, sigma 값, KNN에서의 K값 등등 굉장히 많다. 머신러닝 모델을 쓸 때 사용자가 직접 세팅해야하는 상당히 많다. 그 모든 값이 하이퍼 파라미터이다. 하지만, 많은 사람들이 그 값들을 조정할 때 "모델의 파라미터를 조정한다'는 표현을 쓴다. 원칙적으로는 '모델의 하이퍼파라미터를 조정한다.'라고 해야 한다.

## Validation Sets
Validation Set을 직역하면 '검증데이터 집합'이다. 글자 그대로 '머신러닝 모델을 검증하기 위한 데이터셋' 즉, 성능 평가를 위한 데이터 셋이라고 보면 된다. 

![Cross Validation Sets](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbhzwwY%2FbtqAtbHdeNA%2FpRBnbKySV9asFqpI1Ozc71%2Fimg.png)

- Step1: 주어진 dataset을 training, validation, test dataset들로 나눈다. 일반적으로 각 dataset의 비율은 60:20:20으로 설정한다.
- Step2: Training dataset을 이용하여 모델을 학습시킨다.
- Step3: Validation dataset을 이용하여 모델의 정확도 및 validation dataset에 대한 loss를 계산한다.
- Step4: 만약 Validation loss가 증가했다면 학습을 종료한다. 그렇지 않을 경우에는 (2)로 돌아가서 학습을 계속 진행한다.
- Step5: Test dataset을 이용하여 모델의 최종 정확도를 평가한다.

> 그림의 학습 과정과 기존 training dataset 및 test dataset만을 이용한 학습의 가장 큰 차이점은 Step (3)과 (4)가 추가되었다는 점이다. 이러한 두 과정을 통해 현재의 모델이 학습 과정에서 참조하지 않았던 data를 얼마나 정확하게 예측하는지를 평가하고, 이를 학습의 종료 조건으로 이용함으로써 overfitting을 간접적으로 방지한다.

## Cross Validation
### 교차검증이 쓰이는 이유
- Data pool이 너무 작을 경우
- 고정된 Test set으로 진행한 Performance measure로 인해 Test set에 Overfitting 된 경우

![](https://mblogthumb-phinf.pstatic.net/MjAxOTA3MjVfMTYw/MDAxNTY0MDYxOTQxODg2.2SJCkdADPvofL7LceWnSthfefB3UvnQ2_YoRp5F2vFog.4EZrViOF41rKfovPOJJMyv7W2HKTEvfDyg92pwIIIJ4g.PNG.ckdgus1433/image.png?type=w800)

### 장점
- 모든 데이터 셋을 평가에 활용할 수 있다.
- 평가에 사용되는 데이터 편중을 막을 수 있다.
- 좀 더 일반화 된 모델을 만들 수 있다.
- 데이터 부족으로 인한 Underfitting을 방지할 수 있다.

### 단점
- 반복 횟수가 많아 훈련, 평가 시간이 오래 걸린다.